{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00.000000</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00.000000</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00.000000</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00.000000</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00.000000</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  InvoiceNo StockCode                          Description  \\\n",
       "0           0     536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER   \n",
       "1           1     536365     71053                  WHITE METAL LANTERN   \n",
       "2           2     536365    84406B       CREAM CUPID HEARTS COAT HANGER   \n",
       "3           3     536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE   \n",
       "4           4     536365    84029E       RED WOOLLY HOTTIE WHITE HEART.   \n",
       "\n",
       "   Quantity                 InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0         6  2010-12-01 08:26:00.000000       2.55     17850.0  United Kingdom  \n",
       "1         6  2010-12-01 08:26:00.000000       3.39     17850.0  United Kingdom  \n",
       "2         8  2010-12-01 08:26:00.000000       2.75     17850.0  United Kingdom  \n",
       "3         6  2010-12-01 08:26:00.000000       3.39     17850.0  United Kingdom  \n",
       "4         6  2010-12-01 08:26:00.000000       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('invoice_data.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the dataset is loaded into df (same as before)\n",
    "df_filtered = df[['InvoiceNo', 'StockCode', 'Quantity']]\n",
    "df_filtered = df_filtered[df_filtered['Quantity'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = df_filtered.groupby('InvoiceNo')['StockCode'].apply(set).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(prev_frequent_itemsets, k):\n",
    "    candidates = set()\n",
    "    for itemset1 in prev_frequent_itemsets:\n",
    "        for itemset2 in prev_frequent_itemsets:\n",
    "            if len(itemset1.union(itemset2)) == k:\n",
    "                candidates.add(itemset1.union(itemset2))\n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_support(candidates, transactions):\n",
    "    itemset_counts = {itemset: 0 for itemset in candidates}\n",
    "    \n",
    "    for transaction in transactions:\n",
    "        for itemset in candidates:\n",
    "            if itemset.issubset(transaction):\n",
    "                itemset_counts[itemset] += 1\n",
    "    \n",
    "    total_transactions = len(transactions)\n",
    "    itemset_support = {itemset: count / total_transactions for itemset, count in itemset_counts.items()}\n",
    "    \n",
    "    return itemset_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_itemsets(itemset_support, min_support):\n",
    "    return {itemset: support for itemset, support in itemset_support.items() if support >= min_support}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(transactions, min_support):\n",
    "    items = set(item for transaction in transactions for item in transaction)\n",
    "    candidates = {frozenset([item]) for item in items}\n",
    "    \n",
    "    frequent_itemsets = []\n",
    "    k = 1  # We start with itemsets of length 1\n",
    "    \n",
    "    while candidates:\n",
    "        itemset_support = calculate_support(candidates, transactions)\n",
    "        candidates = prune_itemsets(itemset_support, min_support)\n",
    "        \n",
    "        if not candidates:  # No more frequent itemsets\n",
    "            break\n",
    "        \n",
    "        frequent_itemsets.append(candidates)\n",
    "        k += 1\n",
    "        candidates = generate_candidates(candidates, k)\n",
    "    \n",
    "    return frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rules(frequent_itemsets, itemset_support, min_confidence):\n",
    "    rules = []\n",
    "    \n",
    "    for itemsets in frequent_itemsets:\n",
    "        for itemset in itemsets:\n",
    "            subsets = [frozenset(comb) for i in range(1, len(itemset)) for comb in combinations(itemset, i)]\n",
    "            \n",
    "            for subset in subsets:\n",
    "                antecedent = subset\n",
    "                consequent = itemset - subset\n",
    "                \n",
    "                antecedent_support = itemset_support.get(antecedent, 0)\n",
    "                rule_support = itemset_support.get(itemset, 0)\n",
    "                \n",
    "                if antecedent_support > 0:\n",
    "                    confidence = rule_support / antecedent_support\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((antecedent, consequent, confidence, rule_support))\n",
    "    \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.01  # Minimum support\n",
    "min_confidence = 0.7  # Minimum confidence\n",
    "\n",
    "# Get the frequent itemsets\n",
    "frequent_itemsets = apriori(transactions, min_support)\n",
    "\n",
    "# Calculate the support for itemsets (needed for generating rules)\n",
    "itemset_support = {}\n",
    "for itemsets in frequent_itemsets:\n",
    "    for itemset in itemsets:\n",
    "        itemset_support[itemset] = calculate_support([itemset], transactions).get(itemset, 0)\n",
    "\n",
    "# Generate the association rules\n",
    "rules = generate_rules(frequent_itemsets, itemset_support, min_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how often itemsets appear and plot top itemsets\n",
    "itemset_counts = {itemset: itemset_support[itemset] for itemsets in frequent_itemsets for itemset in itemsets}\n",
    "top_itemsets = sorted(itemset_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of frequent itemsets\n",
    "itemsets, supports = zip(*top_itemsets)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh([str(itemset) for itemset in itemsets], supports, color='skyblue')\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Itemsets')\n",
    "plt.title('Top 10 Frequent Itemsets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_confidences = [(rule[0], rule[1], rule[2]) for rule in rules]\n",
    "if rule_confidences:\n",
    "    antecedents, consequents, confidences = zip(*rule_confidences)\n",
    "    plt.figure(figsize=(20,16))\n",
    "    sns.scatterplot(x=confidences, y=[str(antecedent) + \" -> \" + str(consequent) for antecedent, consequent in zip(antecedents, consequents)])\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Rules')\n",
    "    plt.title('Confidence of Association Rules')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_confidences = [(rule[0], rule[1], rule[2]) for rule in rules]\n",
    "\n",
    "if rule_confidences:\n",
    "    antecedents, consequents, confidences = zip(*rule_confidences)\n",
    "    \n",
    "    # Combine antecedent and consequent for better readability on y-axis\n",
    "    rules_str = [str(antecedent) + \" -> \" + str(consequent) for antecedent, consequent in zip(antecedents, consequents)]\n",
    "    \n",
    "    # Create a DataFrame for better visualization handling\n",
    "    df_rules = pd.DataFrame({\n",
    "        'Rule': rules_str,\n",
    "        'Confidence': confidences\n",
    "    })\n",
    "    \n",
    "    # Sort by confidence for better readability in the bar chart\n",
    "    df_rules = df_rules.sort_values(by='Confidence', ascending=False)\n",
    "\n",
    "    # Plot the bar chart\n",
    "    plt.figure(figsize=(20,18))\n",
    "    sns.barplot(x='Confidence', y='Rule', data=df_rules, palette='viridis')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Rules')\n",
    "    plt.title('Confidence of Association Rules')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that rule_confidences contains (antecedent, consequent, confidence)\n",
    "rule_confidences = [(rule[0], rule[1], rule[2]) for rule in rules]\n",
    "\n",
    "# Extract antecedents, consequents, and confidences separately\n",
    "antecedents, consequents, confidences = zip(*rule_confidences)\n",
    "\n",
    "# Create a DataFrame with antecedents, consequents, and confidences\n",
    "df_rules = pd.DataFrame({\n",
    "    'Antecedent': antecedents,\n",
    "    'Consequent': consequents,\n",
    "    'Confidence': confidences\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate a target variable: 1 for high confidence, 0 for low confidence\n",
    "y = [1 if confidence > 0.8 else 0 for confidence in confidences]\n",
    "\n",
    "# Optional: You can include support or other metrics if needed, but for now, we're focusing on confidence.\n",
    "# For ML model, use just the confidence as a feature\n",
    "X = df_rules[['Confidence']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the DataFrame to check the data\n",
    "print(df_rules.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logreg * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix for Logistic Regression\n",
    "conf_matrix_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
    "print(\"Confusion Matrix for Logistic Regression:\")\n",
    "print(conf_matrix_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier Model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy: {accuracy_dt * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix for Decision Tree\n",
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(conf_matrix_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_logreg)\n",
    "\n",
    "# Decision Tree confusion matrix\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "\n",
    "# Create a figure with two subplots to compare both models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Logistic Regression Confusion Matrix\n",
    "sns.heatmap(cm_lr, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Predicted 0\", \"Predicted 1\"], yticklabels=[\"Actual 0\", \"Actual 1\"], ax=axes[0])\n",
    "axes[0].set_title(\"Logistic Regression Confusion Matrix\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "\n",
    "# Decision Tree Confusion Matrix\n",
    "sns.heatmap(cm_dt, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Predicted 0\", \"Predicted 1\"], yticklabels=[\"Actual 0\", \"Actual 1\"], ax=axes[1])\n",
    "axes[1].set_title(\"Decision Tree Confusion Matrix\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "\n",
    "# Adjust layout for better display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
